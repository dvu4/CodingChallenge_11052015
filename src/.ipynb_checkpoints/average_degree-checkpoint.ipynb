{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {u'#Apache': 1, u'#Spark': 1}, 'time': u'Thu Oct 29 17:51:01 +0000 2015'}\n",
      "{'content': {}, 'time': u'Thu Oct 29 18:10:49 +0000 2015'}\n",
      "{'content': {u'#Apache': 1, u'#Spark': 1}, 'time': u'Thu Oct 29 17:51:01 +0000 2015'}\n",
      "{'content': {u'#Storm': 2, u'#Apache': 2, u'#Hadoop': 2}, 'time': u'Thu Oct 29 17:51:30 +0000 2015'}\n",
      "{'content': {u'#Apache': 0}, 'time': u'Thu Oct 29 17:51:55 +0000 2015'}\n",
      "{'content': {u'#Spark': 1, u'#Flink': 1}, 'time': u'Thu Oct 29 17:51:56 +0000 2015'}\n",
      "{'content': {u'#Spark': 1, u'#HBase': 1}, 'time': u'Thu Oct 29 17:51:59 +0000 2015'}\n",
      "{'content': {u'#Apache': 1, u'#Hadoop': 1}, 'time': u'Thu Oct 29 17:52:05 +0000 2015'}\n"
     ]
    }
   ],
   "source": [
    "# example of program that calculates the number of tweets cleaned\n",
    "\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "#get file path from command line argument in python\n",
    "#infile=open(sys.argv[1],\"r+\")\n",
    "\n",
    "#outfile=open(sys.argv[2],\"w\")\n",
    "\n",
    "#input_file = open(\"../data-gen/tweets.txt\",\"r\")\n",
    "#input_file = open(\"../tweet_input/tweets.txt\",\"r\")\n",
    "input_file = open(\"../tweet_input/tweets_1.txt\",\"r\")\n",
    "\n",
    "\n",
    "def removeNonAscii(s): \n",
    "    if s is not None:\n",
    "        return \"\".join(filter(lambda x: ord(x)<128, s)) \n",
    "\n",
    "def extract_hashtags(s):\n",
    "    return [word for word in s.split() if word[0] == \"#\" ]   \n",
    "    \n",
    "'''\n",
    "d= []\n",
    "for line in input_file:\n",
    "    d.append(json.loads(line))\n",
    "#print type(d)\n",
    "'''    \n",
    "\n",
    "d = [json.loads(line) for line in input_file]\n",
    "\n",
    "result = []\n",
    "unicode_count = 0\n",
    "for line in d:\n",
    "    dic = {}\n",
    "    if  line.get(\"text\") is not None:\n",
    "        dic['time'] = line.get(\"created_at\")\n",
    "        \n",
    "        list_hashtags = extract_hashtags(filter(None,removeNonAscii(line.get(\"text\"))))\n",
    "        \n",
    "        dic1 = {}\n",
    "        for hashtag in list_hashtags:\n",
    "            dic1[hashtag] = len(list_hashtags) -1\n",
    "        dic['content'] = dic1\n",
    "    result.append(dic)\n",
    "        \n",
    "\n",
    "for i in result:\n",
    "    print i\n",
    "\n",
    "\n",
    "\n",
    "# extracting the information of text\" field and  \"created_at\" field, \n",
    "# then output this tweet with the format of \n",
    "# <contents of \"text\" field> (timestamp: <contents of \"created_at\" field>)\n",
    "#with open(\"../tweet_output/ft1.txt\", \"w\") as output_file:\n",
    "#    [output_file.write('{0} (timestamp: {1})\\n'.format(dic['content'], dic['time'])) for dic in result]\n",
    "#    output_file.write('\\n{0} tweets contained unicode.'.format(unicode_count)) \n",
    "\n",
    "#outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2015, 10, 29, 17, 51, 1), datetime.datetime(2015, 10, 29, 17, 51, 30), datetime.datetime(2015, 10, 29, 17, 51, 55), datetime.datetime(2015, 10, 29, 17, 51, 56), datetime.datetime(2015, 10, 29, 17, 51, 59)]\n",
      "[datetime.datetime(2015, 10, 29, 17, 51, 30), datetime.datetime(2015, 10, 29, 17, 51, 55), datetime.datetime(2015, 10, 29, 17, 51, 56), datetime.datetime(2015, 10, 29, 17, 51, 59), datetime.datetime(2015, 10, 29, 17, 52, 5)]\n",
      "[datetime.datetime(2015, 10, 29, 17, 51, 55), datetime.datetime(2015, 10, 29, 17, 51, 56), datetime.datetime(2015, 10, 29, 17, 51, 59), datetime.datetime(2015, 10, 29, 17, 52, 5)]\n",
      "[datetime.datetime(2015, 10, 29, 17, 51, 56), datetime.datetime(2015, 10, 29, 17, 51, 59), datetime.datetime(2015, 10, 29, 17, 52, 5)]\n",
      "[datetime.datetime(2015, 10, 29, 17, 51, 59), datetime.datetime(2015, 10, 29, 17, 52, 5)]\n",
      "[datetime.datetime(2015, 10, 29, 17, 52, 5)]\n"
     ]
    }
   ],
   "source": [
    "time_test = ['Thu Oct 29 17:51:01 +0000 2015',\n",
    "        'Thu Oct 29 17:51:30 +0000 2015',\n",
    "        'Thu Oct 29 17:51:55 +0000 2015',\n",
    "        'Thu Oct 29 17:51:56 +0000 2015',\n",
    "        'Thu Oct 29 17:51:59 +0000 2015',\n",
    "        'Thu Oct 29 17:52:05 +0000 2015']\n",
    "\n",
    "def time_diff(d1,d2):\n",
    "    return (datetime.strptime(d2, \"%a %b %d %H:%M:%S +0000 %Y\") -\n",
    "            datetime.strptime(d1, \"%a %b %d %H:%M:%S +0000 %Y\")).total_seconds()\n",
    "\n",
    "def time_seconds(d):\n",
    "    return datetime.strptime(d, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\n",
    "\n",
    "time_list = [time_seconds(i) for i in time_test]\n",
    "#print time_list\n",
    "#print (time_list[1] - time_list[0]).total_seconds()\n",
    "th=60\n",
    "\n",
    "for i in range(len(time_list)):\n",
    "    print [time_list[i:][idx]  for idx, _ in enumerate(time_list[i:]) if (time_list[i:][idx] - time_list[i:][0]).total_seconds() <= th]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#Apache': 4, '#Spark': 3, '#Storm': 2, '#Hadoop': 3, '#HBase': 1, '#Flink': 1}\n",
      "{u'#CareerArc': 6, u'#Job': 13, u'#Jobs': 27, u'#BusinessMgmt': 15, u'#NettempsJobs': 13, u'#MenloPark,': 9, u'#hiring!': 11}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for d in c: \n",
    "    counter.update(d)\n",
    "print counter\n",
    "d = dict(counter)\n",
    "\n",
    "print d\n",
    "'''\n",
    "from collections import Counter\n",
    "import operator\n",
    "d = dict(reduce(operator.add, map(Counter, c)))\n",
    "print d\n",
    "\n",
    "\n",
    "test = [{'content': {u'#CareerArc': 6, u'#Jobs': 6, u'#NettempsJobs': 6, u'#MenloPark,': 6, u'#Job': 6, u'#BusinessMgmt': 6, u'#hiring!': 6}, \n",
    "        'time': u'Fri Oct 30 15:29:45 +0000 2015'},\n",
    "       {'content': {u'#Jobs': 16, u'#NettempsJobs': 1, u'#MenloPark,': 3, u'#Job': 6, u'#hiring!': 1}, \n",
    "        'time': u'Fri Oct 30 15:32:05 +0000 2015'},\n",
    "       {'content': {u'#Jobs': 5, u'#NettempsJobs': 6, u'#Job': 1, u'#BusinessMgmt': 9, u'#hiring!': 4}, \n",
    "        'time': u'Fri Oct 30 15:39:19 +0000 2015'}]\n",
    "\n",
    "t = [i['content'] for i in test]\n",
    "d = dict(reduce(operator.add, map(Counter, t)))\n",
    "print d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "average degree is: 13.43\n"
     ]
    }
   ],
   "source": [
    "print len(d)\n",
    "avg_degree = 1.0*sum(d.values())/len(d)\n",
    "print 'average degree is: %.2f' %avg_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': [u'#pumpkin', u'#Halloween', u'#HappyHalloween', u'#happyfriday'], 'time': u'Fri Oct 30 15:29:45 +0000 2015'}\n"
     ]
    }
   ],
   "source": [
    "a ={'content': [u'#pumpkin', u'#Halloween', u'#HappyHalloween', u'#happyfriday'], 'time': u'Fri Oct 30 15:29:45 +0000 2015'}\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'#pumpkin', u'#Halloween', u'#HappyHalloween', u'#happyfriday']\n"
     ]
    }
   ],
   "source": [
    "print a['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'#pumpkin': 3, u'#happyfriday': 3, u'#Halloween': 3, u'#HappyHalloween': 3}\n"
     ]
    }
   ],
   "source": [
    "dict1 = {}\n",
    "for i in a['content']:\n",
    "    dict1[i] = len(a['content']) -1\n",
    "print dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date1 = \"Sat Mar 14 18:43:19 +0000 2015\"\n",
    "date2 = \"Sat Mar 14 18:42:49 +0000 2015\"\n",
    "\n",
    "d1 = datetime.strptime(date1, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "d2 = datetime.strptime(date2, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\n",
    "dif = (d1-d2).total_seconds()\n",
    "print dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#Spark', '#Apache'], ['#Apache', '#Hadoop', '#Storm'], ['#Apache'], ['#Flink', '#Spark'], ['#HBase', '#Spark'], ['#Hadoop', '#Apache']]\n",
      "[{'#Apache': 1, '#Spark': 1}, {'#Storm': 2, '#Apache': 2, '#Hadoop': 2}, {'#Apache': 0}, {'#Spark': 1, '#Flink': 1}, {'#Spark': 1, '#HBase': 1}, {'#Apache': 1, '#Hadoop': 1}]\n"
     ]
    }
   ],
   "source": [
    "a= ['Spark Summit East this week! #Spark #Apache (timestamp: Thu Oct 29 17:51:01 +0000 2015)',\n",
    "    'Just saw a great post on Insight Data Engineering #Apache #Hadoop #Storm (timestamp: Thu Oct 29 17:51:30 +0000 2015)',\n",
    "    'Doing great work #Apache (timestamp: Thu Oct 29 17:51:55 +0000 2015)',\n",
    "    'Excellent post on #Flink and #Spark (timestamp: Thu Oct 29 17:51:56 +0000 2015)',\n",
    "    'New and improved #HBase connector for #Spark (timestamp: Thu Oct 29 17:51:59 +0000 2015)',\n",
    "    'New 2.7.1 version update for #Hadoop #Apache (timestamp: Thu Oct 29 17:52:05 +0000 2015)']\n",
    "    \n",
    "b = [extract_hashtags(i) for i in a]\n",
    "print b\n",
    "\n",
    "c=[]\n",
    "for ele in b:\n",
    "    dic1 = {}\n",
    "    for i in ele:\n",
    "        dic1[i] = len(ele) -1\n",
    "    c.append(dic1)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 6, 7, 8, 9, 10, 11, 13, 22, 40]\n"
     ]
    }
   ],
   "source": [
    "s = [1,3,5,6,7,8,9,10,11,13,22,40]\n",
    "print s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the correct sequence of list is (with  difference of the fisrt and last element equal 5 )\n",
    "[1, 3, 5, 6]\n",
    "[3, 5, 6, 7, 8]\n",
    "[5, 6, 7, 8, 9, 10]\n",
    "[6, 7, 8, 9, 10, 11]\n",
    "[7, 8, 9, 10, 11]\n",
    "[8, 9, 10, 11, 13]\n",
    "[9,10,11,13]\n",
    "[10,11,13]\n",
    "[11]\n",
    "[13]\n",
    "[22]\n",
    "[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 6, 7, 8]\n",
      "length of new list is: 5\n",
      "Length of original list is: 12\n"
     ]
    }
   ],
   "source": [
    "th = 5\n",
    "e = []\n",
    "for idx, val in enumerate(s):\n",
    "    if s[idx] - s[1] <= th:\n",
    "        e.append(s[idx])\n",
    "        \n",
    "print e\n",
    "print 'length of new list is:',len(e)-1 \n",
    "print 'Length of original list is:',len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print [s[0:][idx]  for idx, _ in enumerate(s[0:]) if s[0:][idx] - s[0:][0] <= th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print [s[1:][idx]  for idx, _ in enumerate(s[1:]) if s[1:][idx] - s[1:][0] <= th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print [s[2:][idx]  for idx, _ in enumerate(s[2:]) if s[2:][idx] - s[2:][0] <= th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print [s[3:][idx]  for idx, _ in enumerate(s[3:]) if s[3:][idx] - s[3:][0] <= th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 6]\n",
      "[3, 5, 6, 7, 8]\n",
      "[5, 6, 7, 8, 9, 10]\n",
      "[6, 7, 8, 9, 10, 11]\n",
      "[7, 8, 9, 10, 11]\n",
      "[8, 9, 10, 11, 13]\n",
      "[9, 10, 11, 13]\n",
      "[10, 11, 13]\n",
      "[11, 13]\n",
      "[13]\n",
      "[22]\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(s)):\n",
    "    print [s[i:][idx]  for idx, _ in enumerate(s[i:]) if s[i:][idx] - s[i:][0] <= th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
