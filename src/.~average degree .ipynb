{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': {}, 'time': u'Thu Oct 29 17:51:50 +0000 2015'}, {'content': {}, 'time': u'Thu Oct 29 17:51:51 +0000 2015'}, {'content': {}, 'time': u'Thu Oct 29 18:10:49 +0000 2015'}, {'content': {}, 'time': u'Thu Oct 29 18:10:49 +0000 2015'}, {'content': {}, 'time': u'Thu Oct 29 18:10:49 +0000 2015'}, {'content': {}, 'time': u'Thu Oct 29 18:10:49 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {u'#Trump': 2, u'#Election': 2, u'#News': 2}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Ifievergettocabo': 0}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Careerarc': 6, u'#Jobs': 6, u'#Nettempsjobs': 6, u'#Menlopark,': 6, u'#Job': 6, u'#Businessmgmt': 6, u'#Hiring!': 6}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:44 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Rhonda': 1, u'#Hangry': 1}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Laliga': 1, u'#Football': 1}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Deterrorenlabomba': 0}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Pumpkin': 3, u'#Happyfriday': 3, u'#Halloween': 3, u'#Happyhalloween': 3}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Diadelosmuertos': 0}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {u'#Surprisenrjlimoges': 0}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {'content': {}, 'time': u'Fri Oct 30 15:29:45 +0000 2015'}, {}]\n"
     ]
    }
   ],
   "source": [
    "# example of program that calculates the average degree of hashtags\n",
    "\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "#get file path from command line argument in python\n",
    "#infile=open(sys.argv[1],\"r+\")\n",
    "#outfile=open(sys.argv[2],\"w\")\n",
    "\n",
    "\n",
    "\n",
    "#input_file = open(\"../data-gen/tweets.txt\",\"r\")\n",
    "input_file = open(\"../tweet_input/tweets.txt\",\"r\")\n",
    "#input_file = open(\"../tweet_input/tweets_1.txt\",\"r\")\n",
    "\n",
    "def extract_hashtags(s):\n",
    "    hashtags = [word.lower().title() for word in s.split() if word[0] == \"#\"]\n",
    "    return list(set(hashtags))\n",
    "\n",
    "\n",
    "def removeNonAscii(s): \n",
    "    if s is not None:\n",
    "        return \"\".join(filter(lambda x: ord(x)<128, s)) \n",
    "\n",
    "d= []\n",
    "for line in input_file:\n",
    "    d.append(json.loads(line))\n",
    "\n",
    "result = []\n",
    "unicode_count = 0\n",
    "for line in d:\n",
    "    dic = {}\n",
    "    if  line.get(\"text\") is not None:\n",
    "        dic['time'] = line.get(\"created_at\")\n",
    "\n",
    "        #dic['content'] = filter(None,removeNonAscii(line.get(\"text\")))\n",
    "        \n",
    "        list_hashtags = extract_hashtags(filter(None,removeNonAscii(line.get(\"text\"))))\n",
    "        #print list_hashtags\n",
    "\n",
    "        dic1 = {}\n",
    "        for hashtag in list_hashtags:\n",
    "            dic1[hashtag] = len(list_hashtags) - 1\n",
    "            \n",
    "        dic['content'] = dic1\n",
    "        \n",
    "    result.append(dic)\n",
    "    \n",
    "print result\n",
    "\n",
    "\n",
    "        \n",
    "#with open(\"../tweet_output/ft2.txt\", \"w\") as output_file:\n",
    "#    [output_file.write('{0} ({1})\\n'.format(', '.join(extract_hashtags(dic['content'])),\n",
    "#                                            dic['time'])) for dic in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "d1 = datetime.datetime.strptime(result[53]['time'], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "d2 = datetime.datetime.strptime(result[10]['time'], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "dif = (d1-d2).total_seconds()\n",
    "\n",
    "print dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 30 15:29:44 +0000 2015\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-375c9ddae1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0md_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%a %b %d %H:%M:%S +0000 %Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0md_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%a %b %d %H:%M:%S +0000 %Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtime_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print result[9]['time']\n",
    "time_window = 60\n",
    "\n",
    "for i in range(len(result)):\n",
    "    d_start = datetime.datetime.strptime(result[i]['time'], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "    d_end = datetime.datetime.strptime(result[i+1]['time'], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "    \n",
    "    time_diff = (d_end - d_start).total_seconds()\n",
    "    if  time_diff <= time_window:\n",
    "        print 'ok'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Spark is kicking off a new #spark project in #SPARK era\n",
      "['#Spark']\n"
     ]
    }
   ],
   "source": [
    "def extract_hashtags(s):\n",
    "    hashtags = [word.lower().title() for word in s.split() if word[0] == \"#\"]\n",
    "    return list(set(hashtags))\n",
    " \n",
    "    \n",
    "test = '#Spark is kicking off a new #spark project in #SPARK era'\n",
    "print test\n",
    "print extract_hashtags(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#Apache', '#Spark'], ['#Storm', '#Apache', '#Hadoop'], ['#Apache'], ['#Spark', '#Flink']]\n",
      "['#Storm', '#Apache', '#Hadoop']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "a = ['Spark Summit East this week! #Spark #Apache (timestamp: Thu Oct 29 17:51:01 +0000 2015)',\n",
    "     'Just saw a great post on Insight Data Engineering #Apache #Hadoop #Storm (timestamp: Thu Oct 29 17:51:30 +0000 2015)',\n",
    "     'Doing great work #Apache (timestamp: Thu Oct 29 17:51:55 +0000 2015)',\n",
    "     'Excellent post on #Flink and #Spark (timestamp: Thu Oct 29 17:51:56 +0000 2015)']\n",
    "\n",
    "b = [extract_hashtags(line) for line in a]\n",
    "print b\n",
    "\n",
    "b1 = extract_hashtags(a[1])\n",
    "print b1\n",
    "\n",
    "b2 = extract_hashtags('\\n')\n",
    "print b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'#Apache': 1, '#Spark': 1}, {'#Storm': 2, '#Apache': 2, '#Hadoop': 2}, {'#Apache': 0}, {'#Spark': 1, '#Flink': 1}]\n"
     ]
    }
   ],
   "source": [
    "dict1 = []\n",
    "for ele in b:\n",
    "    c = {}\n",
    "    for i in ele:\n",
    "        c[i] = len(ele) - 1 \n",
    "    dict1.append(c)\n",
    "print dict1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#Storm': 2, '#Apache': 3, '#Hadoop': 2, '#Spark': 2, '#Flink': 1}\n",
      "average degree is:  2.00\n"
     ]
    }
   ],
   "source": [
    "# the Twitter Hashtag Graph in 60 second window\n",
    "\n",
    "import collections\n",
    "counter = collections.Counter()\n",
    "for d in dict1: \n",
    "    counter.update(d)\n",
    "\n",
    "dict2 = dict(counter)\n",
    "print dict2\n",
    "\n",
    "\n",
    "# The rolling average degree\n",
    "avg_deg = 1.0*sum(dict2.values())/len(dict2)\n",
    "print 'average degree is: % .2f' % avg_deg\n",
    "\n",
    "#outfile.write(format(np.median(set_word),'.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 1, 'two': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(one=1, two=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00\n"
     ]
    }
   ],
   "source": [
    "print '%.2f' %5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "s1 = 'Feb 12 08:02:32 2015'\n",
    "s2 = 'Jan 27 11:52:02 2014'\n",
    "\n",
    "s2 = 'Thu Oct 29 17:51:55 +0000 2015'\n",
    "s1 = 'Thu Oct 29 17:51:56 +0000 2015'\n",
    "\n",
    "\n",
    "d1 = datetime.datetime.strptime(s1, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "d2 = datetime.datetime.strptime(s2, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "dif = (d1-d2)\n",
    "\n",
    "print dif.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Summit East this week! #Spark #Apache  Thu Oct 29 17:51:01 +0000 2015\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cleanString = re.sub('\\(+|\\)|timestamp:','', a[0] )\n",
    "print cleanString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
